{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  USC EE559 Final Project Spring 2021\n",
    "#  Online News Popularity Prediction\n",
    "## Mingjian Shi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0. Performance Measure\n",
    "#Trivial system\n",
    "def self_MSE(y):\n",
    "    y_m = np.mean(y)\n",
    "    MSE = 0\n",
    "    for i in range(np.size(y)):\n",
    "        MSE = MSE + (y[i] - y_m)**2\n",
    "    MSE = MSE/np.size(y)\n",
    "    return MSE\n",
    "\n",
    "\n",
    "#Calculate p_MSE\n",
    "#def p_MSE(y_train,y_predict):\n",
    "    #pMSE = 0\n",
    "    #r = 10\n",
    "    #for i in range(np.size(y_train)):\n",
    "        #pMSE = pMSE + ((y_train[i] - y_predict[i]) / (r + y_train[i]))**2\n",
    "    #pMSE = pMSE / np.size(y_train)\n",
    "    #return pMSE\n",
    "\n",
    "# Under the help of our TA, we changed p_MSE to the following\n",
    "def p_MSE(y, y_pred):\n",
    "    diff = (y - y_pred)/(y+10)\n",
    "    pMSE = np.mean(np.power(diff, 2))\n",
    "    return pMSE\n",
    "\n",
    "\n",
    "#Calculate p_MAE\n",
    "#def p_MAE(y_train, y_predict):\n",
    "    #pMAE = 0\n",
    "    #r = 10\n",
    "    #for i in range(np.size(y_train)):\n",
    "        #pMAE = pMAE + np.abs((y_train[i] - y_predict[i]) / (y_train[i] + r))\n",
    "    #pMAE = pMAE / np.size(y_train)\n",
    "    #return pMAE\n",
    "    \n",
    "# Under the help of our TA, we changed p_MAE to the following    \n",
    "def p_MAE(y, y_pred):\n",
    "    diff = (y - y_pred)/(y+10)\n",
    "    pMAE = np.mean(np.abs(diff))\n",
    "    return pMAE\n",
    "\n",
    "#Calculate R_squared \n",
    "def R_squared(y_train, y_predict):\n",
    "    y_mse = self_MSE(y_train)\n",
    "    y_pre_mse = mean_squared_error(y_train,y_predict)\n",
    "    rSquared = 1 - y_pre_mse/y_mse\n",
    "    return rSquared\n",
    "#Calculate Modified R_squared\n",
    "def modified_R_squared(y_train, y_predict,pMSE):\n",
    "    m_R = 0\n",
    "    r = 10\n",
    "    modified = 0\n",
    "    y_mean = np.mean(y_train)\n",
    "    for i in range(np.size(y_train)):\n",
    "        modified = modified + ((y_train[i] - y_mean) / (r + y_train[i]))**2\n",
    "    modified = modified / np.size(y_train) \n",
    "    m_R = 1 - (pMSE / modified)\n",
    "    return m_R\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data and Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire Training Data Set:  (35644, 58) \n",
      "\n",
      "Data after Down-Sampling:  (3564, 58) \n",
      "\n",
      "Entire Test Data Set: (2000, 58)\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "#1. Load Data\n",
    "#Training set\n",
    "orig_train = 'NEWS_Training_data.csv'\n",
    "orig_label = 'NEWS_Training_label.csv'\n",
    "df_orig_train_data = pd.read_csv(orig_train, header = 0)\n",
    "df_orig_label_data = pd.read_csv(orig_label, header = 0)\n",
    "\n",
    "#Test set\n",
    "test_data = 'NEWS_Test_data.csv'\n",
    "test_label = 'NEWS_Test_label.csv'\n",
    "X_orig_test = pd.read_csv(test_data, header = 0)\n",
    "Y_orig_test = pd.read_csv(test_label, header = 0)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "#Down Sampling \n",
    "df_data = pd.concat([df_orig_train_data,df_orig_label_data],axis=1)\n",
    "\n",
    "down_sample = df_data.sample(frac = 0.1)\n",
    "down_sample.shape\n",
    "\n",
    "#Split label and data\n",
    "df_orig_train = down_sample.drop(['shares'],axis =1)\n",
    "df_orig_label = down_sample['shares']\n",
    "\n",
    "print('Entire Training Data Set: ',np.shape(df_orig_train_data),'\\n')\n",
    "print('Data after Down-Sampling: ',np.shape(df_orig_train),'\\n')\n",
    "\n",
    "print('Entire Test Data Set:', np.shape(X_orig_test))\n",
    "#---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Remove Outliers\n",
    "## (We didn't use it eventually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Outlier\n",
    "\n",
    "#First, lets take a look at the labels distribution\n",
    "df_orig_label_data.hist(bins = 50, figsize = (10,10))\n",
    "plt.title('Original shares data')\n",
    "plt.show()\n",
    "\n",
    "#Let's take a look at the shares<10000\n",
    "df_label = df_orig_label_data[df_orig_label_data<10000]\n",
    "df_label.hist(bins = 50, figsize = (10,10))\n",
    "plt.title('Shares data for #shares<10000')\n",
    "plt.show()\n",
    "print('Median:', np.median(df_orig_label_data),'\\n')\n",
    "print('Mean:', np.mean(df_orig_label_data),'\\n')\n",
    "print('Std:', np.std(df_orig_label_data),'\\n')\n",
    "print('(Median+2std):',np.median(df_orig_label_data) + 2*np.std(df_orig_label_data),'\\n') \n",
    "print('(median-2std):',np.mean(df_orig_label_data) - 2*np.std(df_orig_label_data),'\\n')\n",
    "print('Data size for #shares<10000\\n',df_label[df_label['shares']<10000].shape)\n",
    "#We found out using Median can better represent the data based on #shares\n",
    "#We narrow our data range from 0 to (median + 2*std) \n",
    "m = np.median(df_orig_label_data)\n",
    "std = np.std(df_orig_label_data)\n",
    "drop_limit = m + 2*std\n",
    "df_data = pd.concat([df_orig_train_data,df_orig_label_data],axis=1)\n",
    "df_data = df_data[df_data['shares'] < int(drop_limit)]\n",
    "\n",
    "df_orig_train = df_data.drop(['shares'],axis =1)\n",
    "df_orig_label = df_data['shares']\n",
    "df_orig_label.hist(bins = 50, figsize = (10,10))\n",
    "plt.title('Narrowed Shares data (median + 2*std)')\n",
    "plt.show()\n",
    "\n",
    "#Compare data size After outliers were removed\n",
    "print('Data size before remove outlier',np.shape(df_orig_train_data),'\\n')\n",
    "print('Data size after remove outlier',np.shape(df_orig_train),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Combine Features and Feature Engineering \n",
    "## (We didn't Combine any features eventually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Feature\n",
    "df_train = df_orig_train\n",
    "\n",
    "#There are features can be combined into one new feature\n",
    "#Some thoughts are from https://towardsdatascience.com/using-columntransformer-to-combine-data-processing-steps-af383f7d5260\n",
    "def FeaturesCombine(input_data, original_f, combined_f):\n",
    "    \n",
    "    index = 0\n",
    "    input_data[combined_f] = index\n",
    "    \n",
    "    for feature_name in original_f:\n",
    "        index += 1\n",
    "        input_data.loc[input_data[feature_name] == 1, combined_f] = index\n",
    "        input_data = input_data.drop([feature_name], axis = 1)\n",
    "        \n",
    "    return input_data\n",
    "\n",
    "#We found the weekdays category can be merged to a new features called weekdays with values from 1-7 to represent Mon-Sun\n",
    "days = ['weekday_is_monday','weekday_is_tuesday','weekday_is_wednesday','weekday_is_thursday','weekday_is_friday','weekday_is_saturday','weekday_is_sunday']\n",
    "df_train = FeaturesCombine(df_train, days, 'weekdays')\n",
    "\n",
    "#We found the data_channles can be merged to a new features called data_channels with 1-6 represent lifestyle to world catagory\n",
    "channels = ['data_channel_is_lifestyle', 'data_channel_is_entertainment', 'data_channel_is_bus', 'data_channel_is_socmed','data_channel_is_tech','data_channel_is_world'] \n",
    "df_train = FeaturesCombine(df_train, channels, 'data_channels')\n",
    "np_train = np.array(df_train)\n",
    "np_label = np.array(df_orig_label)\n",
    "\n",
    "print('After FeatureCombine',np_train.shape,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Split into Training and Validation Set(DownSampled Data):\n",
      "\n",
      "X_train Size: (2851, 58)\n",
      "Y_train Size: (2851,)\n",
      "X_Val Size: (713, 58)\n",
      "Y_Val Size: (713,) \n",
      "\n",
      "2.Split into Training and Validation Set(Entire Data set):\n",
      "\n",
      "X_train_all Size: (28515, 58)\n",
      "Y_train_all Size: (28515,)\n",
      "X_Val_all Size: (7129, 58)\n",
      "Y_Val_all Size: (7129,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "\n",
    "#Split Train and Val \n",
    "\n",
    "# 1.For DownSampled Data\n",
    "X_train = np.array(df_orig_train)\n",
    "Y_train = np.array(df_orig_label)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state =40)\n",
    "\n",
    "print('1.Split into Training and Validation Set(DownSampled Data):\\n')\n",
    "print('X_train Size:',X_train.shape)\n",
    "print('Y_train Size:',Y_train.shape)\n",
    "print('X_Val Size:',X_val.shape)\n",
    "print('Y_Val Size:',Y_val.shape,'\\n')\n",
    "\n",
    "# 2.For Entire Data Set \n",
    "df_data_all = pd.concat([df_orig_train_data,df_orig_label_data],axis=1)\n",
    "df_train_all = df_data_all.drop(['shares'],axis =1)\n",
    "df_label_all = df_data_all['shares']\n",
    "X_train_all = np.array(df_train_all)\n",
    "Y_train_all = np.array(df_label_all)\n",
    "X_train_all, X_val_all, Y_train_all, Y_val_all = train_test_split(X_train_all, Y_train_all, test_size = 0.2, random_state =40)\n",
    "\n",
    "print('2.Split into Training and Validation Set(Entire Data set):\\n')\n",
    "print('X_train_all Size:',X_train_all.shape)\n",
    "print('Y_train_all Size:',Y_train_all.shape)\n",
    "print('X_Val_all Size:',X_val_all.shape)\n",
    "print('Y_Val_all Size:',Y_val_all.shape,'\\n')\n",
    "\n",
    "#--------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Normalization for DownSampled Data Completed......\n",
      "\n",
      "2.Normalization for Entire Data set Completed......\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------\n",
    "\n",
    "#Normalize Data\n",
    "\n",
    "# 1.For DownSampled Data\n",
    "scaler1 = StandardScaler()\n",
    "scaler1.fit(X_train)\n",
    "X_train = scaler1.transform(X_train)\n",
    "X_val = scaler1.transform(X_val)\n",
    "\n",
    "print('1.Normalization for DownSampled Data Completed......\\n')\n",
    "\n",
    "# 2.For Entire Data Set (Training)\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(X_train_all)\n",
    "X_train_all = scaler1.transform(X_train_all)\n",
    "X_val_all = scaler1.transform(X_val_all)\n",
    "print('2.Normalization for Entire Data set Completed......\\n')\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Regression with different Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Trival System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trival sys MSE: [1.40846919e+08]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trival System \n",
    "y_mse = self_MSE(df_orig_label_data.to_numpy())\n",
    "print('Trival sys MSE:', y_mse)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Baseline Model\n",
      "MAE: 2798.4787747951978\n",
      "pMSE: 6.93660065041956\n",
      "pMAE: 1.5713788322876932\n",
      "R_squared: 0.04423602205078592\n",
      "Modified_R_Squared: 0.20344363931290588\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "train_data = df_orig_train_data.to_numpy()\n",
    "train_label = df_orig_label_data.to_numpy()\n",
    "train_label = train_label[:,0]\n",
    "\n",
    "X_test = X_orig_test.to_numpy()\n",
    "Y_test = Y_orig_test.to_numpy()\n",
    "Y_test = Y_test[:,0]\n",
    "\n",
    "#Normalize Training and Test data\n",
    "scaler_best = StandardScaler()\n",
    "scaler_best.fit(train_data)\n",
    "train_data = scaler_best.transform(train_data)\n",
    "test_data = scaler_best.transform(X_test)\n",
    "\n",
    "\n",
    "#Using Linear Regression to Training and test to report the base line model\n",
    "reg_lin = LinearRegression().fit(train_data, train_label)\n",
    "test_pred = reg_lin.predict(test_data)\n",
    "\n",
    "#Performance Measure\n",
    "MAE = mean_absolute_error(Y_test,test_pred)\n",
    "pMSE = p_MSE(Y_test,test_pred)\n",
    "pMAE = p_MAE(Y_test,test_pred)\n",
    "rSquared = R_squared(Y_test,test_pred)\n",
    "m_rSquared = modified_R_squared(Y_test, test_pred, pMSE)\n",
    "print('Linear Regression Baseline Model')\n",
    "print('MAE:',MAE)\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)\n",
    "print('R_squared:', rSquared)\n",
    "print('Modified_R_Squared:',m_rSquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------\n",
    "# SVR with 5 fold Cross validation \n",
    "def SVRCrossValidation(x_train, y_train):\n",
    "    kf = KFold(n_splits=5)\n",
    "    gamma_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "    C_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "    pMSE = np.zeros([np.size(gamma_), np.size(C_)], dtype=float)\n",
    "    pMAE = np.zeros([np.size(gamma_), np.size(C_)], dtype=float)\n",
    "\n",
    "    #For each gamma, try each C\n",
    "    for Ng, g in enumerate(gamma_):\n",
    "        for Nc, c in enumerate(C_):\n",
    "            k = 0\n",
    "            pmse_av = 0\n",
    "            pmae_av = 0\n",
    "            pmse = np.zeros([5, 1], dtype=float)\n",
    "            pmae = np.zeros([5, 1], dtype=float)\n",
    "            #split\n",
    "            for train_index, val_index in kf.split(x_train, y_train):\n",
    "                data_train, data_val = x_train[train_index], x_train[val_index]\n",
    "                label_train, label_val = y_train[train_index], y_train[val_index]\n",
    "                #Define the model\n",
    "                reg = SVR(C=c, kernel='rbf', gamma=g)\n",
    "                reg.fit(data_train, label_train)\n",
    "                y_pred = reg.predict(data_val)\n",
    "                pmse[k] = p_MSE(label_val, y_pred)\n",
    "                pmae[k] = p_MAE(label_val, y_pred)\n",
    "                k += 1\n",
    "            pmse_av = np.mean(pmse)\n",
    "            pmae_av = np.mean(pmae)\n",
    "            pMSE[Ng,Nc] = pmse_av\n",
    "            pMAE[Ng,Nc] = pmae_av\n",
    "    return pMSE, pMAE\n",
    "\n",
    "#SVR using validation and training(No Cross validation)\n",
    "def SVRVal(x_train, y_train,x_val,y_val):\n",
    "    gamma_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "    C_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "    pMSE = np.zeros([np.size(gamma_), np.size(C_)], dtype=float)\n",
    "    pMAE = np.zeros([np.size(gamma_), np.size(C_)], dtype=float)\n",
    "    \n",
    "    for Ng, g in enumerate(gamma_):\n",
    "        for Nc, c in enumerate(C_):\n",
    "            #Define the model\n",
    "            reg = SVR(C=c, kernel='rbf', gamma=g)\n",
    "            reg.fit(x_train, y_train)\n",
    "            y_pred = reg.predict(x_val)\n",
    "            \n",
    "            #Store the value in     \n",
    "            pMSE[Ng,Nc] = p_MSE(y_val,y_pred)\n",
    "            pMAE[Ng,Nc] = p_MAE(y_val,y_pred)\n",
    "    return pMSE, pMAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 SVR Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the performance \n",
    "pMSE,pMAE = SVRVal(X_train, Y_train, X_val, Y_val)\n",
    "\n",
    "gamma_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "C_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "\n",
    "#Find the best parameters based on MSE\n",
    "# if there are more than one best MSE, choose the one with best MAE\n",
    "def findBestPara_MSE(pMSE,pMAE):\n",
    "    best_mse = np.min(pMSE)\n",
    "    Ng_best,Nc_best = np.where(pMSE == best_mse)\n",
    "    if np.size(Ng_best) == 1:\n",
    "        return Ng_best,Nc_best\n",
    "    else:# if the best is not the only one, we need to find based on MAE\n",
    "        candidate_pmae = np.zeros([np.size(Ng_best),1],dtype = float)\n",
    "        for i in range(np.size(Ng_best)):\n",
    "            candidate_pmae[i] = pMAE[Ng_best[i],Nc_best[i]]\n",
    "        best_mae = np.min(candidate_pmae)\n",
    "        i,j = np.where(candidate_pmae == best_mae)\n",
    "        return Ng_best[i[0]],Nc_best[i[0]]\n",
    "#call the function \n",
    "Ng_best, Nc_best = findBestPara_MSE(pMSE,pMAE)\n",
    "\n",
    "print('SVR Best Model(MSE Based):')\n",
    "print('Best gamma:',gamma_[Ng_best])\n",
    "print('Best C:',C_[Nc_best])\n",
    "print('Best pMSE:',pMSE[Ng_best,Nc_best])\n",
    "print('Best pMAE:',pMAE[Ng_best,Nc_best])\n",
    "print('Best Ng',Ng_best)\n",
    "print('Best Nc',Nc_best,'\\n')\n",
    "\n",
    "\n",
    "#Find the best parameters based on MAE\n",
    "# if there are more than one best MAE, choose the one with best MSE\n",
    "def findBestPara_MAE(pMSE,pMAE):\n",
    "    best_mae = np.min(pMAE)\n",
    "    Ng_best,Nc_best = np.where(pMAE == best_mae)\n",
    "    if np.size(Ng_best) == 1:\n",
    "        return Ng_best,Nc_best\n",
    "    else:# if the best is not the only one, we need to find based on MSE\n",
    "        candidate_pmse = np.zeros([np.size(Ng_best),1],dtype = float)\n",
    "        for i in range(np.size(Ng_best)):\n",
    "            candidate_pmse[i] = pMSE[Ng_best[i],Nc_best[i]]\n",
    "        best_mse = np.min(candidate_pmse)\n",
    "        i,j = np.where(candidate_pmse == best_mse)\n",
    "        return Ng_best[i[0]],Nc_best[i[0]]\n",
    "#call the function\n",
    "Ng_best, Nc_best = findBestPara_MAE(pMSE,pMAE)\n",
    "\n",
    "print('SVR Best Model(MAE Based):')\n",
    "print('Best gamma:',gamma_[Ng_best])\n",
    "print('Best C:',C_[Nc_best])\n",
    "print('Best pMSE:',pMSE[Ng_best,Nc_best])\n",
    "print('Best pMAE:',pMAE[Ng_best,Nc_best])\n",
    "print('Best Ng',Ng_best)\n",
    "print('Best Nc',Nc_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 SVR Model 1:  [g,C] = [0.00719686, 138.94954944] (Validation Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with [g,C] = [0.00719686, 138.94954944]:\n",
      "pMSE: 1.1536588181895415\n",
      "pMAE: 0.5709751439138046\n"
     ]
    }
   ],
   "source": [
    "#After the previous step \n",
    "#We find two best pairs for SVR\n",
    "\n",
    "#1.[g,C] = [0.00719686, 138.94954944]\n",
    "#2.[g,C] = [0.00719686, 79.06043211]\n",
    "\n",
    "#Then we run on all the data 2 times for the 2 best pairs and compare:\n",
    "gamma_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "C_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "\n",
    "#1st Run with [g,C] = [0.00719686, 138.94954944]\n",
    "svr1 = SVR(C=C_[42], kernel='rbf', gamma=gamma_[7])\n",
    "svr1.fit(X_train_all, Y_train_all)\n",
    "Y_pred_all = svr1.predict(X_val_all)\n",
    "pMSE = p_MSE(Y_val_all,Y_pred_all)\n",
    "pMAE = p_MAE(Y_val_all,Y_pred_all)\n",
    "print('SVR with [g,C] = [0.00719686, 138.94954944]:')\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 SVR Model 2: [g,C] = [0.00719686, 79.06043211] (Validation Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd Run SVR with [g,C] = [0.00719686, 79.06043211]:\n",
      "pMSE: 1.1389524902128147\n",
      "pMAE: 0.5698028364365723\n"
     ]
    }
   ],
   "source": [
    "#2nd Run with [g,C] = [0.00719686, 79.06043211]\n",
    "\n",
    "svr2 = SVR(C=C_[40], kernel='rbf', gamma=gamma_[7])\n",
    "svr2.fit(X_train_all, Y_train_all)\n",
    "Y_pred_all = svr2.predict(X_val_all)\n",
    "pMSE = p_MSE(Y_val_all,Y_pred_all)\n",
    "pMAE = p_MAE(Y_val_all,Y_pred_all)\n",
    "rSquared = R_squared(Y_val_all,Y_pred_all)\n",
    "print('2nd Run SVR with [g,C] = [0.00719686, 79.06043211]:')\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 SVR Model selection Results:\n",
    "#### Based on the 2 SVR Models, we find Model 2 is better! \n",
    "#### Model Parameters: [g,C] = [0.00719686, 79.06043211]\n",
    "#### Validation Results: \n",
    "#### pMSE: 1.15148983507122\n",
    "#### pMAE: 0.5700800579704007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 Report Best SVR Model(Entire Training Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVR Model\n",
      " [g,C] = [gamma_[7], C_[40]] = [0.00719686, 79.06043211]:\n",
      "\n",
      "MAE: 2226.0999205355274\n",
      "pMSE: 1.1389524902128147\n",
      "pMAE: 0.5698028364365723\n",
      "R_squared: -0.015921993152419933\n",
      "Modified_R_Squared: 0.8701497349230467\n",
      "-0.015921993152438585\n"
     ]
    }
   ],
   "source": [
    "#Gamma and C\n",
    "gamma_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "C_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "\n",
    "#Best C is the 40th C, best gamma is 7th\n",
    "svr_best = SVR(C=C_[40], kernel='rbf', gamma=gamma_[7])\n",
    "svr_best.fit(X_train_all, Y_train_all)\n",
    "Y_pred_all = svr_best.predict(X_val_all)\n",
    "\n",
    "#Performance Measure\n",
    "pMSE = p_MSE(Y_val_all,Y_pred_all)\n",
    "pMAE = p_MAE(Y_val_all,Y_pred_all)\n",
    "rSquared = R_squared(Y_val_all,Y_pred_all)\n",
    "m_rSquared = modified_R_squared(Y_val_all, Y_pred_all, pMSE)\n",
    "MAE = mean_absolute_error(Y_val_all,Y_pred_all)\n",
    "print('Best SVR Model\\n [g,C] = [gamma_[7], C_[40]] = [0.00719686, 79.06043211]:\\n')\n",
    "print('MAE:',MAE)\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)\n",
    "print('R_squared:', rSquared)\n",
    "print('Modified_R_Squared:',m_rSquared)\n",
    "print(svr_best.score(X_val_all, Y_val_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Non-Linear Regression with PolyFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Linear Regression with PolyFeature(2-3)\n",
      "pMSE:\n",
      " [[1.41582926e+22]\n",
      " [9.59203000e+02]]\n",
      "pMAE:\n",
      " [[7.32488935e+09]\n",
      " [9.48216817e+00]]\n"
     ]
    }
   ],
   "source": [
    "#With Cross Validation \n",
    "def polyCrossValidation(x_train, y_train, min_M, max_M):\n",
    "    kf = KFold(n_splits=5)\n",
    "    poly_order = np.linspace(min_M, max_M, num = max_M - min_M+1)\n",
    "    pMSE = np.zeros([max_M - min_M +1, 1], dtype=float)\n",
    "    pMAE = np.zeros([max_M - min_M +1, 1], dtype=float)\n",
    "    \n",
    "    for Nm, m in enumerate(poly_order):\n",
    "        k = 0\n",
    "        pmse_av = 0\n",
    "        pmae_av = 0\n",
    "        pmse = np.zeros([5, 1], dtype=float)\n",
    "        pmae = np.zeros([5, 1], dtype=float)\n",
    "        poly = PolynomialFeatures(degree = int(m))\n",
    "        #Split\n",
    "        for train_index, val_index in kf.split(x_train, y_train):\n",
    "            data_train, data_val = x_train[train_index], x_train[val_index]\n",
    "            label_train, label_val = y_train[train_index], y_train[val_index]\n",
    "            #Poly transform\n",
    "            data_train_expand = poly.fit_transform(data_train)\n",
    "            data_val_expand = poly.fit_transform(data_val)\n",
    "            #Define the model, fit and predict \n",
    "            reg = LinearRegression().fit(data_train_expand, label_train)\n",
    "            y_pred = reg.predict(data_val_expand)\n",
    "            pmse[k] = p_MSE(label_val, y_pred)\n",
    "            pmae[k] = p_MAE(label_val, y_pred)\n",
    "            k += 1\n",
    "        #Store the values\n",
    "        pmse_av = np.mean(pmse)\n",
    "        pmae_av = np.mean(pmae)\n",
    "        pMSE[Nm] = pmse_av\n",
    "        pMAE[Nm] = pmae_av\n",
    "    return pMSE, pMAE\n",
    "\n",
    "\n",
    "\n",
    "#without cross validation \n",
    "def polyVal(x_train, y_train,x_val,y_val, min_M, max_M):\n",
    "    \n",
    "    poly_order = np.linspace(min_M, max_M, num = max_M - min_M+1)\n",
    "    pMSE = np.zeros([max_M - min_M +1, 1], dtype=float)\n",
    "    pMAE = np.zeros([max_M - min_M +1, 1], dtype=float)\n",
    "    \n",
    "    for Nm, m in enumerate(poly_order):\n",
    "        #poly feature transform\n",
    "        poly = PolynomialFeatures(degree = int(m))\n",
    "        data_train_expand = poly.fit_transform(x_train)\n",
    "        data_val_expand = poly.fit_transform(x_val)\n",
    "        #Define the model, fit and predict \n",
    "        reg = LinearRegression().fit(data_train_expand, y_train)\n",
    "        y_pred = reg.predict(data_val_expand)\n",
    "        \n",
    "        pMSE[Nm] = p_MSE(y_val,y_pred)\n",
    "        pMAE[Nm] = p_MAE(y_val,y_pred)\n",
    "    return pMSE, pMAE\n",
    "\n",
    "\n",
    "\n",
    "#Ploy degree from 2 to 3 \n",
    "pMSE, pMAE = polyVal(X_train, Y_train,X_val,Y_val, 2, 3)\n",
    "print('Non-Linear Regression with PolyFeature(2-3)')\n",
    "print('pMSE:\\n', pMSE)\n",
    "print('pMAE:\\n', pMAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Linear Regression with PolyFeature 4\n",
      "pMSE: 689376.4219384738\n",
      "pMAE: 61.591328662149465\n"
     ]
    }
   ],
   "source": [
    "# The Above result is too bad, we try poly order 4 with PCA feature Reduction \n",
    "\n",
    "#Using PCA to reduce features to 20\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components = 20).fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "#PolyFeature Transform with degree=4\n",
    "poly = PolynomialFeatures(degree = 4)\n",
    "data_train_expand = poly.fit_transform(X_train_pca)\n",
    "data_val_expand = poly.fit_transform(X_val_pca)\n",
    "reg = LinearRegression().fit(data_train_expand, Y_train)\n",
    "Y_pred = reg.predict(data_val_expand)\n",
    "\n",
    "#Calulate PMSE and PMAE\n",
    "pMSE = p_MSE(Y_val,Y_pred)\n",
    "pMAE = p_MAE(Y_val,Y_pred)\n",
    "print('Non-Linear Regression with PolyFeature 4')\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Non-Linear Regression with PolyFeatures Result:\n",
    "#### We found the best poly order is 3 \n",
    "#### Validation Results:\n",
    "#### pMSE: 3.08009484e+04\n",
    "#### pMAE: 1.08889408e+01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Report Best Non-Linear Regression Model(Entire Training Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PolyFeature Transform with degree=3\n",
    "poly_best = PolynomialFeatures(degree = 3)\n",
    "data_train_expand = poly_best.fit_transform(X_train_all)\n",
    "data_val_expand = poly_best.fit_transform(X_val_all)\n",
    "\n",
    "#Regression model\n",
    "reg_best = LinearRegression().fit(data_train_expand, Y_train_all)\n",
    "Y_pred_all = reg_best.predict(data_val_expand)\n",
    "\n",
    "#Performance\n",
    "MAE = mean_absolute_error(Y_val_all,Y_pred_all)\n",
    "pMSE = p_MSE(Y_val_all,Y_pred_all)\n",
    "pMAE = p_MAE(Y_val_all,Y_pred_all)\n",
    "rSquared = R_squared(Y_val_all,Y_pred_all)\n",
    "m_rSquared = modified_R_squared(Y_val_all, Y_pred_all, pMSE)\n",
    "print('Best Non-Linear Regression(PolyFeature=3)')\n",
    "print('MAE:',MAE)\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)\n",
    "print('R_squared:', rSquared)\n",
    "print('Modified_R_Squared:',m_rSquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression with Poly degree 1-2::\n",
      "pMSE:\n",
      " [[ 11.52411335  11.53149948  11.54073863  11.55207274  11.56562143\n",
      "   11.58127119  11.59854507  11.61648978  11.63364174  11.64813896\n",
      "   11.65801336  11.66162872  11.65815064  11.64788314  11.63229967\n",
      "   11.61364237  11.59407609  11.57457895  11.5539792   11.52866309\n",
      "   11.49331727  11.44263918  11.37348957  11.28677616  11.18853431\n",
      "   11.09002824  11.0069645   10.95795533  10.9622788   11.03697192\n",
      "   11.1935275   11.43488726  11.75374554  12.13305427  12.54891956\n",
      "   12.97509095  13.38756724  13.76792394  14.10469924  14.3930255\n",
      "   14.63319279  14.8288784   14.9855493   15.10926666  15.20591784\n",
      "   15.28079918  15.33844433  15.38260392  15.41630659  15.44195545]\n",
      " [238.10646022 229.36832661 219.11647597 207.48210515 194.71806842\n",
      "  181.17648464 167.26116504 153.37452203 139.87697752 127.06419235\n",
      "  115.15560679 104.28650708  94.50318875  85.76687962  77.97062546\n",
      "   70.96703351  64.59991504  58.73225015  53.26507138  48.14470911\n",
      "   43.35871871  38.92369407  34.87013763  31.22914319  28.022955\n",
      "   25.25884867  22.92539619  20.99144574  19.40873557  18.11796971\n",
      "   17.0566479   16.1665217   15.39940038  14.72113106  14.11393989\n",
      "   13.57679752  13.12280301  12.77284569  12.54645634  12.45283513\n",
      "   12.48569141  12.62382488  12.83648233  13.0905757   13.35687949\n",
      "   13.61367526  13.84774379  14.05342999  14.23070426  14.38298234]]\n",
      "pMAE:\n",
      " [[1.92770349 1.92792301 1.92817329 1.92850854 1.92888863 1.92919641\n",
      "  1.92933196 1.92917537 1.9288127  1.9281121  1.92691811 1.92478418\n",
      "  1.92156738 1.91711312 1.91115008 1.90375265 1.89504123 1.88508129\n",
      "  1.87382922 1.86147755 1.84764784 1.83286301 1.81840162 1.80348757\n",
      "  1.79032107 1.78273887 1.78023844 1.78183607 1.78810114 1.79997669\n",
      "  1.81582637 1.83673475 1.86034014 1.88580018 1.91083479 1.9342255\n",
      "  1.95555683 1.97443699 1.99063787 2.00451127 2.0159053  2.02495943\n",
      "  2.03206952 2.03760116 2.0418969  2.04521103 2.04776327 2.04972223\n",
      "  2.0512402  2.05239215]\n",
      " [5.76129828 5.67379314 5.57294842 5.46159691 5.34042301 5.21344915\n",
      "  5.07785696 4.93682213 4.79362492 4.65067862 4.51009626 4.36594112\n",
      "  4.22265182 4.08168059 3.943683   3.80688245 3.68574016 3.56518912\n",
      "  3.44034577 3.31681485 3.19101574 3.06343686 2.93944399 2.81513168\n",
      "  2.69127092 2.57075555 2.4605212  2.35699889 2.26396658 2.18358998\n",
      "  2.11633842 2.07196131 2.03350338 2.00183509 1.97445212 1.95473534\n",
      "  1.942916   1.9405822  1.94183222 1.95006314 1.95966007 1.9693135\n",
      "  1.97835434 1.98656351 1.99358591 1.99957601 2.00454628 2.00864365\n",
      "  2.01194408 2.01469226]]\n"
     ]
    }
   ],
   "source": [
    "#Ridge Regression with 5 fold cross validation \n",
    "def RidgeCrossValidation(x_train, y_train, min_M, max_M):\n",
    "    kf = KFold(n_splits=5)\n",
    "    poly_order = np.linspace(min_M, max_M, num = max_M - min_M+1)\n",
    "    pMSE = np.zeros([max_M - min_M +1, 50], dtype=float)\n",
    "    pMAE = np.zeros([max_M - min_M +1, 50], dtype=float)\n",
    "\n",
    "    alphas = np.logspace(-3, 3, 50, base=10)\n",
    "    \n",
    "    for Nm, m in enumerate(poly_order):\n",
    "        for Na, a in enumerate(alphas):\n",
    "            \n",
    "            k = 0\n",
    "            pmse_av = 0\n",
    "            pmae_av = 0\n",
    "            pmse = np.zeros([5, 1], dtype=float)\n",
    "            pmae = np.zeros([5, 1], dtype=float)\n",
    "            poly = PolynomialFeatures(degree = int(m))\n",
    "            for train_index, val_index in kf.split(x_train, y_train):\n",
    "                data_train, data_val = x_train[train_index], x_train[val_index]\n",
    "                label_train, label_val = y_train[train_index], y_train[val_index]\n",
    "                #Poly fit transformation\n",
    "                data_train_expand = poly.fit_transform(data_train)\n",
    "                data_val_expand = poly.fit_transform(data_val)\n",
    "                #Ridge Regression fit and predict\n",
    "                ridge = Ridge(alpha = a)\n",
    "                ridge.fit(data_train_expand, label_train)\n",
    "                y_pred = ridge.predict(data_val_expand)\n",
    "                pmse[k] = p_MSE(label_val, y_pred)\n",
    "                pmae[k] = p_MAE(label_val, y_pred)\n",
    "                k += 1\n",
    "            pmse_av = np.mean(pmse)\n",
    "            pmae_av = np.mean(pmae)\n",
    "            pMSE[Nm,Na] = pmse_av\n",
    "            pMAE[Nm,Na] = pmae_av\n",
    "    return pMSE, pMAE\n",
    "\n",
    "# Ridge Without cross validation \n",
    "def RidgeVal(x_train, y_train,x_val,y_val, min_M, max_M):\n",
    "    \n",
    "    poly_order = np.linspace(min_M, max_M, num = max_M - min_M+1)\n",
    "    pMSE = np.zeros([max_M - min_M +1, 50], dtype=float)\n",
    "    pMAE = np.zeros([max_M - min_M +1, 50], dtype=float)\n",
    "\n",
    "    alphas = np.logspace(0, 6, 50, base=10)\n",
    "    \n",
    "    for Nm, m in enumerate(poly_order):\n",
    "        \n",
    "        poly = PolynomialFeatures(degree = int(m))\n",
    "        #Poly fit transformation\n",
    "        data_train_expand = poly.fit_transform(x_train)\n",
    "        data_val_expand = poly.fit_transform(x_val)\n",
    "        \n",
    "        for Na, a in enumerate(alphas):\n",
    "        \n",
    "            #Ridge Regression fit and predict\n",
    "            ridge = Ridge(alpha = a)\n",
    "            ridge.fit(data_train_expand, y_train)\n",
    "            y_pred = ridge.predict(data_val_expand)\n",
    "                \n",
    "            pMSE[Nm,Na] = p_MSE(y_val, y_pred)\n",
    "            pMAE[Nm,Na] = p_MAE(y_val, y_pred)\n",
    "    return pMSE, pMAE\n",
    "\n",
    "\n",
    "#Ploy degree from 1 to 2\n",
    "pMSE, pMAE = RidgeVal(X_train, Y_train, X_val, Y_val, 1, 2)\n",
    "print('Ridge Regression with Poly degree 1-2::')\n",
    "print('pMSE:\\n', pMSE)\n",
    "print('pMAE:\\n', pMAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Find the best poly order M and alpha for Ridge Regrssion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best pmse is happended in M =1\n",
    "best_pmse_list = pMSE[0]\n",
    "\n",
    "#Find the best M and Alpha based on the best pmse list which is Poly Order 1\n",
    "best_pmse = np.min(best_pmse_list)\n",
    "best_index = np.where(best_pmse_list == best_pmse)\n",
    "alphas = np.logspace(0, 6, 50, base=10)\n",
    "best_alpha = alphas[best_index] \n",
    "print('Best Alpha is:', best_alpha)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Report the Validation Result  For Ridge Regression(Entire Training data)\n",
    "### under the Best M and alpha:\n",
    "#### Best M = 1\n",
    "#### Best alpha = 2023.58964773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression Model(On Entire Data Set)\n",
      "(poly order M=1, alpha = 2023.58964773)\n",
      "MAE: 2980.8640797484436\n",
      "pMSE: 8.810311914869368\n",
      "pMAE: 1.6891806743341236\n",
      "R_squared: 0.026793606627427913\n",
      "Modified_R_Squared: -0.004450446693054166\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree = 1)\n",
    "#Poly fit transformation\n",
    "X_train_expand = poly.fit_transform(X_train_all)\n",
    "X_val_expand = poly.fit_transform(X_val_all)\n",
    "\n",
    "ridge = Ridge(alpha = 2023.58964773)\n",
    "ridge.fit(X_train_expand, Y_train_all)\n",
    "Y_pred_all = ridge.predict(X_val_expand)\n",
    "\n",
    "#Performance Measurement \n",
    "MAE = mean_absolute_error(Y_val_all,Y_pred_all)\n",
    "pMSE = p_MSE(Y_val_all,Y_pred_all)\n",
    "pMAE = p_MAE(Y_val_all,Y_pred_all)\n",
    "rSquared = R_squared(Y_val_all,Y_pred_all)\n",
    "m_rSquared = modified_R_squared(Y_val_all, Y_pred_all, pMSE)\n",
    "print('Best Ridge Regression Model(On Entire Data Set)\\n(poly order M=1, alpha = 2023.58964773)')\n",
    "print('MAE:',MAE)\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)\n",
    "print('R_squared:', rSquared)\n",
    "print('Modified_R_Squared:',m_rSquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 KNN\n",
    "#### Since KNN runs fast, we will use the whole data set for Training and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression(Entire Data Set):\n",
      "pMSE:\n",
      " [[14.98001292]\n",
      " [13.02720829]\n",
      " [11.5422054 ]\n",
      " [10.90776939]\n",
      " [10.57448586]\n",
      " [10.96239722]\n",
      " [10.2111965 ]\n",
      " [10.16886223]\n",
      " [ 9.65904242]\n",
      " [ 9.34504953]\n",
      " [ 8.95708318]\n",
      " [ 8.93919191]\n",
      " [ 9.17997126]\n",
      " [ 9.19342601]\n",
      " [ 9.02648365]\n",
      " [ 9.15755031]]\n",
      "pMAE:\n",
      " [[1.49429489]\n",
      " [1.4620734 ]\n",
      " [1.45508871]\n",
      " [1.46410538]\n",
      " [1.46849502]\n",
      " [1.46912377]\n",
      " [1.45976684]\n",
      " [1.45408917]\n",
      " [1.44972021]\n",
      " [1.44969397]\n",
      " [1.44632021]\n",
      " [1.44688108]\n",
      " [1.45547524]\n",
      " [1.46207498]\n",
      " [1.45855727]\n",
      " [1.45426138]]\n"
     ]
    }
   ],
   "source": [
    "#KNN with cross validation \n",
    "def KNNCrossValidation(x_train, y_train):\n",
    "    kf = KFold(n_splits=5)\n",
    "    K_ = np.linspace(5,15,num=11)\n",
    "    pMSE = np.zeros([11, 1], dtype=float)\n",
    "    pMAE = np.zeros([11, 1], dtype=float)\n",
    "    \n",
    "    for Nk, k in enumerate(K_):\n",
    "        j = 0\n",
    "        pmse_av = 0\n",
    "        pmae_av = 0\n",
    "        pmse = np.zeros([5, 1], dtype=float)\n",
    "        pmae = np.zeros([5, 1], dtype=float)\n",
    "        neigh = KNeighborsRegressor(n_neighbors=int(k))\n",
    "        for train_index, val_index in kf.split(x_train, y_train):\n",
    "            data_train, data_val = x_train[train_index], x_train[val_index]\n",
    "            label_train, label_val = y_train[train_index], y_train[val_index]\n",
    "            \n",
    "            neigh.fit(data_train, label_train)\n",
    "            y_pred = neigh.predict(data_val)\n",
    "            pmse[j] = p_MSE(label_val, y_pred)\n",
    "            pmae[j] = p_MAE(label_val, y_pred)\n",
    "            j += 1\n",
    "        pmse_av = np.mean(pmse)\n",
    "        pmae_av = np.mean(pmae)\n",
    "        pMSE[Nk] = pmse_av\n",
    "        pMAE[Nk] = pmae_av\n",
    "    return pMSE, pMAE\n",
    "\n",
    "\n",
    "#Without Cross Validation \n",
    "def KNNVal(x_train, y_train, x_val, y_val):\n",
    "    \n",
    "    K_ = np.linspace(5,20,num=16)\n",
    "    pMSE = np.zeros([16, 1], dtype=float)\n",
    "    pMAE = np.zeros([16, 1], dtype=float)\n",
    "    \n",
    "    for Nk, k in enumerate(K_):\n",
    "        #Define the model, fit and predict \n",
    "        neigh = KNeighborsRegressor(n_neighbors=int(k))\n",
    "        neigh.fit(x_train, y_train)\n",
    "        y_pred = neigh.predict(x_val)\n",
    "\n",
    "        pMSE[Nk] = p_MSE(y_val, y_pred)\n",
    "        pMAE[Nk] = p_MAE(y_val, y_pred)\n",
    "    return pMSE, pMAE\n",
    "\n",
    "#KNN Regression\n",
    "pMSE, pMAE = KNNVal(X_train_all, Y_train_all, X_val_all, Y_val_all)\n",
    "print('KNN Regression(Entire Data Set):')\n",
    "print('pMSE:\\n', pMSE)\n",
    "print('pMAE:\\n', pMAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 KNN Model Parameters and Validation Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression Model:\n",
      "Best K for KNN: 5.0\n",
      "pMSE: 1.1389524902128147\n",
      "pMAE: 0.5698028364365723\n"
     ]
    }
   ],
   "source": [
    "#Find Best K \n",
    "K_ = np.linspace(5,20,num=16)\n",
    "best_K_index = np.where(pMSE == np.min(pMSE))\n",
    "best_K = K_[best_K_index[0]]\n",
    "print('KNN Regression Model:')\n",
    "print('Best K for KNN:', best_K[0])\n",
    "print('pMSE:', np.min(pMSE))\n",
    "print('pMAE:', np.min(pMAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Report Best KNN Model Validation Result (Entire Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Model(On Entire Data Set)\n",
      "(K=16)\n",
      "MAE: 2908.810886870529\n",
      "pMSE: 8.939191908350137\n",
      "pMAE: 1.4468810825132776\n",
      "R_squared: -0.006969376991294185\n",
      "Modified_R_Squared: -0.019143861440728882\n"
     ]
    }
   ],
   "source": [
    "knn_best = KNeighborsRegressor(n_neighbors=16)\n",
    "knn_best.fit(X_train_all, Y_train_all)\n",
    "Y_pred_all = knn_best.predict(X_val_all)\n",
    "\n",
    "#Performance Measurement \n",
    "MAE = mean_absolute_error(Y_val_all,Y_pred_all)\n",
    "pMSE = p_MSE(Y_val_all,Y_pred_all)\n",
    "pMAE = p_MAE(Y_val_all,Y_pred_all)\n",
    "rSquared = R_squared(Y_val_all,Y_pred_all)\n",
    "m_rSquared = modified_R_squared(Y_val_all, Y_pred_all, pMSE)\n",
    "print('Best KNN Model(On Entire Data Set)\\n(K=16)')\n",
    "print('MAE:',MAE)\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)\n",
    "print('R_squared:', rSquared)\n",
    "print('Modified_R_Squared:',m_rSquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Finalize the best Model\n",
    "#### We choose SVR with [g,C] = [gamma_[7], C_[40]] = [0.00719686, 79.06043211]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run best model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model(SVR)\n",
      "pMSE: 1.9488751498926589\n",
      "pMAE: 0.7151657983768334\n",
      "R_squared: [-0.03669242]\n",
      "Modified_R_Squared: [0.77620322]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Load data\n",
    "train_data = df_orig_train_data.to_numpy()\n",
    "train_label = df_orig_label_data.to_numpy()\n",
    "train_label = train_label[:,0]\n",
    "\n",
    "X_test = X_orig_test.to_numpy()\n",
    "Y_test = Y_orig_test.to_numpy()\n",
    "\n",
    "\n",
    "#Normalize Training and Test data\n",
    "scaler_best = StandardScaler()\n",
    "scaler_best.fit(train_data)\n",
    "train_data = scaler_best.transform(train_data)\n",
    "test_data = scaler_best.transform(X_test)\n",
    "\n",
    "#Fit and Predict model \n",
    "\n",
    "#Gamma and C\n",
    "gamma_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "C_ = np.logspace(-3, 3, num=50, base=10.0)\n",
    "\n",
    "#Best C is the 40th C, best gamma is 7th\n",
    "model = SVR(C=C_[40], kernel='rbf', gamma=gamma_[7])\n",
    "model.fit(train_data, train_label)\n",
    "test_pred = model.predict(test_data)\n",
    "\n",
    "#Performance Measure\n",
    "pMSE = p_MSE(Y_test,test_pred)\n",
    "pMAE = p_MAE(Y_test,test_pred)\n",
    "rSquared = R_squared(Y_test,test_pred)\n",
    "m_rSquared = modified_R_squared(Y_test, test_pred, pMSE)\n",
    "print('Best Model(SVR)')\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)\n",
    "print('R_squared:', rSquared)\n",
    "print('Modified_R_Squared:',m_rSquared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save .pkl File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model(SVR)\n",
      "pMSE: 1.9488751498926589\n",
      "pMAE: 0.7151657983768334\n",
      "R_squared: [-0.03669242]\n",
      "Modified_R_Squared: [0.77620322]\n"
     ]
    }
   ],
   "source": [
    "#Pipe Line\n",
    "pipe = Pipeline([('scaler', scaler_best), ('svr', model)])\n",
    "test_pred = pipe.predict(X_test)\n",
    "\n",
    "pMSE = p_MSE(Y_test,test_pred)\n",
    "pMAE = p_MAE(Y_test,test_pred)\n",
    "rSquared = R_squared(Y_test,test_pred)\n",
    "m_rSquared = modified_R_squared(Y_test, test_pred, pMSE)\n",
    "print('Best Model(SVR)')\n",
    "print('pMSE:',pMSE)\n",
    "print('pMAE:',pMAE)\n",
    "print('R_squared:', rSquared)\n",
    "print('Modified_R_Squared:',m_rSquared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A model has been saved as model_NEWS.pkl\n"
     ]
    }
   ],
   "source": [
    "#Save Best Model\n",
    "alias = \"NEWS\"\n",
    "filename = \"model_{}.pkl\".format(alias)\n",
    "pickle.dump(pipe, open(filename, 'wb'))\n",
    "print(\"A model has been saved as {}\".format(filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
